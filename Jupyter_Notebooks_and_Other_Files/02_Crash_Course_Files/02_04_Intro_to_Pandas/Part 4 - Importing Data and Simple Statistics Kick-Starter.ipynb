{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CEE Masthead](http://kyrill.ias.sdsmt.edu/wjc/eduresources/CEE_284_Masthead.png)\n",
    "# Part 4 -- Importing Data and Simple Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "This session is a throwback to earlier on the semester when we worked with the Concrete exercises.\n",
    "\n",
    "The idea here is to replicate what we did in our statistics sections.  At some point you will be taking  [MATH 381 (Intro to Probability and Stats)](http://ecatalog.sdsmt.edu/preview_course_nopop.php?catoid=17&coid=26571) which will be your official introduction to “R.” R tends to be the go-to package for statistics. Like Python it’s open source. But at some point, you may need to do this type of analysis in the python environment.\n",
    "\n",
    "This session also has a link to a R notebook that attacks our Concrete exercises with gusto.\n",
    "\n",
    "The Python exercise will scratch the surface on getting basic stats and doing a couple linear and multivariate regressions.\n",
    "\n",
    "\n",
    "\n",
    "## Libraries\n",
    "\n",
    "We will be using some familiar libraries for this activity.\n",
    "\n",
    "* [NumPy](https://numpy.org/doc/1.17/reference/index.html) our basic numerical python libraries\n",
    "* [SciPy's Advanced Stats Functions](https://docs.scipy.org/doc/scipy/reference/stats.html): A subset of SciPy which requires a separate load from its stats package area (as seen below), and  \n",
    "* [Matplotlib](https://matplotlib.org): Our print library from MatPlotLib\n",
    "\n",
    "* We will also use a package called [\"Pandas\"](https://pandas.pydata.org/index.html) \"Python Data Analysis\" Libraries which is frequently used in wrestling and wrangling with data.\n",
    "\n",
    "* We are going to be cracking open an excel spreadsheet which requires a [xlrd](https://xlrd.readthedocs.io/en/latest/).  You won't personally be calling this library, it will accessed within pandas when you ingest the excel spreadsheet.\n",
    "\n",
    "* Finally, we'll need use a more advanced set of machine learning libraries to process our linear regression part of the exercise. [sklearn](https://scikit-learn.org/stable/index.html) a machine learning toolkit.  \n",
    "\n",
    "sklearn and xlrd may not be in your Anaconda build.  You may need to import this using your anaconda interface, which we'll do together in our classroom session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Library Calls.\n",
    "#\n",
    "# Numpy Library\n",
    "\n",
    "import numpy                as np\n",
    "\n",
    "# SciPy's Stats Library\n",
    "\n",
    "import scipy.stats          as stats\n",
    "\n",
    "# Plotting Libraries\n",
    "\n",
    "import matplotlib.pyplot    as plt\n",
    "\n",
    "# Pandas Library \n",
    "\n",
    "import pandas               as pd\n",
    "\n",
    "# Excel Support Library\n",
    "\n",
    "import xlrd                 as xlrd\n",
    "\n",
    "# Machine Learning Support Library\n",
    "\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn              as skl\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cracking Open Data\n",
    "\n",
    "Before we move forward as with large amounts of data, you aren't going to want to manually install the fields you will want to crunch.\n",
    "\n",
    "The good news is that Pandas has some [nice resources](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) to pull in data from typical sources that we use.\n",
    "\n",
    "Even better news is that there are resources that will allow you to access data over the internet. For this exercise this is a godsend since we won't have to panic over where to get our dataset.\n",
    "\n",
    "Speaking of which, our dataset can be found at the CEE 284 Python page and also at the following scary looking URL.\n",
    "\n",
    "If you were working the a local file on desktop you would use the lower two examples depending on what machine you are using. But for us now we will use the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# URL for our Excel Spreadsheet\n",
    "#\n",
    "\n",
    "url_excel_location = \"http://kyrill.ias.sdsmt.edu/wjc/eduresources/Base_Concrete_Slump_Test_for_R.xlsx\"\n",
    "\n",
    "#\n",
    "# Examples of what the location path to your home desktop *may* look like\n",
    "#\n",
    "\n",
    "local_MacOS_or_UNIX_desktop_location =  \"~/Desktop/Base_Concrete_Slump_Test_for_R.xlsx\"\n",
    "local_Windows_desktop_location       = \"Y:\\Desktop\\Base_Concrete_Slump_Test_for_R.xlsx\"\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a fast look at that file (I just have the screenshot here). Notice that the A column is just a list of the test number.  And we are going to use that with the load command.  It's also on a page called \"Data\" and you can install a single page at your choice.\n",
    "\n",
    "![Concrete Spreadsheet Screenshot](http://kyrill.ias.sdsmt.edu/wjc/eduresources/Base_Concrete_Slump_Test_for_R.png)\n",
    "\n",
    "The good news is that it's pretty easy to read an excel sheet regardless of the location of the file.  \n",
    "\n",
    "The command is Panda's [pandas.read_excel](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-excel-reader).  An example of cracking our file with minimal effort, maximum satisfaction is here.\n",
    "\n",
    "This will work best if your spreadsheet is arranged as a simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Opening a spreadsheet with read_excel in Pandas\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at data quickly you can use the print command..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# fast and fugly with the print() command\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That test number column isn't really in the \"meat\" of the dataset.  It's in index.  If the first column in the spreadsheet is real data (not just a line counter), don't use the \"index_col\" command.\n",
    "\n",
    "To look at the data quickly so it's *pretty*, use the display command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# fast and purdy with the display command()\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsettting Groups of Variables\n",
    "\n",
    "In oru dataset we have two groups of variables.  We have the Independant Values to the left and the three rightmost Dependant Variables.  \n",
    "\n",
    "We can break these up which will make later plotting and statistics much easier.  \n",
    "\n",
    "As with numpy arrays, panda data frames are objects (called [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)) and can be queried and manipulated via attributes and internal objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Splitting Variables between Independant and Dependant Variables\n",
    "#\n",
    "#   The Dependant Variables are the rightmost three fields.  We can extract \n",
    "#       them using the method below.   \n",
    "\n",
    "\n",
    "#   For the Independant values, let's use a tool in the pandas data object \n",
    "#       called \"drop\"  This is easier for us than doing the \n",
    "#       above when we had enter each  values.\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Mom and Apple Pie Statistics\n",
    "\n",
    "Let's do some basic statistics.  let's do the mean, standard deviation (sample), count, skewness and kurtosis.  You can get those in the [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#computations-descriptive-stats) or [NumPy](https://numpy.org/doc/1.17/reference/routines.statistics.html) descriptive libraries.\n",
    "\n",
    "We'll use Pandas's functions here.  Along with a DataFrame we can create another data object called a \"[panda.Series](https://pandas.pydata.org/pandas-docs/stable/reference/series.html)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> counts for Cement\n",
      "\n",
      "\n",
      ">>> data_means\n",
      "\n",
      "\n",
      ">>> data_skew\n",
      "\n",
      "\n",
      ">>> data_kurtosis\n",
      "\n",
      "\n",
      ">>> data_kurtosis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Examples of with SciPy Stats\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "# Since one column may have missing data\n",
    "#  you may need to do this one field at a time\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Outputs\n",
    "#\n",
    "\n",
    "print(\">>> counts for Cement\")\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\">>> data_means\")\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\">>> data_skew\")\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\">>> data_kurtosis\")\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\">>> data_kurtosis\")\n",
    "print()\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For much of this exercise, let's only look at one parameter:  Compressive Strength.\n",
    "\n",
    "Let's start with some simple plots.\n",
    "\n",
    "## Histograms\n",
    "\n",
    "Histograms are acutally pretty easy.  There is a function in MATLAB that does this and as such, there is an analog in python via [matplotlib.pyplot.hist](https://www.google.com/search?client=safari&rls=en&q=pyplot.hist&ie=UTF-8&oe=UTF-8)\n",
    "\n",
    "Also as with other functions in matlab you can add certain elements of the plotted output needed to make the graph.  You can normalize the plot to fit a probability distribution as shown here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Histogram (Matplotlib version)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "#\n",
    "# Plotting Histogram (Matplotlib version as a density plot)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an object attached to panda series that makes a histogram with [pandas.DataFrame.plot.hist](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist) and [pandas.Series.plot.hist](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.hist.html).  \n",
    "\n",
    "Additonally there are specialized functions to do probability density fields similar to R  using [pandas.DataFrame.plot.density](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html) and [pandas.Series.plot.density](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.density.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Histograms (Pandas version)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################\n",
    "\n",
    "\n",
    "##########################################################\n",
    "#\n",
    "# Plotting Probability Density (Pandas version)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can take the latter field and overlay a normal distrubition atop it. (While this is dataset is not a normal distribution, this is mostly for demonstration reasons here and also to set things up later in this exercise when we play rough with confidence intervals.  \n",
    "\n",
    "To do this we are going to create a simple normal distribution.  Fortunately scipy.stats.* has a resource for that.  (It has resources for a number of probability distributions, including the $t$ distribution).\n",
    "\n",
    "The normal distribution object in scipy.stats is [scipy.stats.norm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html).  One of the resources to that object is \"pdf\" for the probability distribution, \"cdf\" for a cumulative distribution from $-\\infty$ to a given x, and an inverse cdf function called \"ppf\" that gets the $x$ value you want for a given $p(x)$.  We'll be using the latter go get the t-statistic for confidence intervals below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-07a00977e980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# create a simple x-axis vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m x_vector = np.linspace(np.min(data.Compressive_Strength_28dy),\n\u001b[0m\u001b[1;32m     10\u001b[0m                        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompressive_Strength_28dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                        100)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting a density-based histogram with a normal distribution.\n",
    "#\n",
    "\n",
    "#\n",
    "# create a simple x-axis vector \n",
    "#\n",
    "x_vector = np.linspace(np.min(data.Compressive_Strength_28dy),\n",
    "                       np.max(data.Compressive_Strength_28dy),\n",
    "                       100)\n",
    "\n",
    "\n",
    "z_pdf = stats.norm.pdf(x_vector,\n",
    "                       np.mean(data.Compressive_Strength_28dy),  # mean goes here (loc in the docs)\n",
    "                       np.std(data.Compressive_Strength_28dy))   # stdev goes here (spread in the docs)\n",
    "\n",
    "plt.hist(data.Compressive_Strength_28dy, \n",
    "         density =True,\n",
    "         color   = \"r\")\n",
    "plt.plot(x_vector,\n",
    "         z_pdf,\n",
    "         \"k\")\n",
    "plt.legend([\"$p_{norm}(x)$\",\n",
    "            \"Histogram\"])\n",
    "plt.title(\"Yeh Concrete Tests (density)\")\n",
    "plt.xlabel(\"28-dy Compressive Strength (Pa)\")\n",
    "plt.ylabel(\"Probability Density, p(x)\")\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Whisker Plots\n",
    "\n",
    "The function [matplotlib.pyplot.boxplot](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html) will make a boxplot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Box Whisker (single value version)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we frequency use Boxwhisker plots (and violin plots) to have a downward perspective in our data so we can see multiple fields at once.  Let's try this again using our independant values.\n",
    "\n",
    "BUT here we have to use another tool for the plotting:  We are working with a pandas data frame.  But luckily there is a operator that hangs off the pandas data object called [pandas.DataFrame.boxplot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Box Whisker (Panda's multiple version)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of other packages that make spiffy plots such as [Seaborn](https://seaborn.pydata.org/index.html#).  But for now we're keeping things simple.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Confidence Interval with SciPy.Stats \n",
    "\n",
    "How about Confidence Intervals on the mean?  For this we WILL need to dig into the deeper areas of SciPy into their stats libraries.  We'll need the [t-stastic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#scipy.stats.t) for our alpha.  This is a little scary so we'll walk it through one step at a time.\n",
    "\n",
    "Let's also use this as a chance to play with graphics so let's milk this opportunity as muhc as we can.  \n",
    "\n",
    "### The Student's-T Distribution\n",
    "\n",
    "Let's fetch the Student's T function. For this we will pull thee pdf from the scipy.stats.t.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting the PDF for t.\n",
    "#\n",
    "\n",
    "t_vector = np.linspace(-3,3,101)\n",
    "\n",
    "df = data_count - 1\n",
    "\n",
    "t_pdf_df    = stats.t(df).pdf(t_vector)    # our value\n",
    "t_pdf_dfInf = stats.t(99999).pdf(t_vector) # \"infinity\"\n",
    "t_pdf_df10  = stats.t(10).pdf(t_vector)    # df = 10\n",
    "t_pdf_df05  = stats.t(5).pdf(t_vector)     # df = 5\n",
    "t_pdf_df02  = stats.t(2).pdf(t_vector)     # df = 2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(t_vector, t_pdf_dfInf, \"k\",\n",
    "         t_vector, t_pdf_df,    \"purple\",\n",
    "         t_vector, t_pdf_df10,  \"b\",\n",
    "         t_vector, t_pdf_df05,  \"g\",\n",
    "         t_vector, t_pdf_df02,  \"r\")\n",
    "plt.axhline(y = 0, color = \"grey\")\n",
    "plt.legend([\"df = $\\infty$\",\n",
    "            \"df = \" + str(df),\n",
    "            \"df = 10\",\n",
    "            \"df =  5\",\n",
    "            \"df =  2\"])\n",
    "plt.title(\"Probability Density for Student's-t\")\n",
    "plt.ylabel(\"probability densitiy function, $p(t)$\")\n",
    "plt.xlabel(\"normalized $t$\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ok let's play.... \n",
    "\n",
    "This isn't germaine to getting confidence intervals, but who cares, let's play with some plotting tricks.\n",
    "\n",
    "recall that the t statistic is \n",
    "\n",
    "$$t = \\frac{x - \\mu_x}{s_x / \\sqrt{n}}$$.\n",
    "\n",
    "When we look at this plot it would be helpful to see where the t distribution of the expected population mean, $\\mu_x$\n",
    "\n",
    "So arguably we could demonstrate how to overlay our original stats.\n",
    "\n",
    "With a little Algebra-Fu... we can solve for x.\n",
    "\n",
    "$$x = \\mu_x + t \\frac{s_x}{\\sqrt{n}}$$ \n",
    "\n",
    "So let's overlay that field atop our earlier probability density histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Scaling and displaying our PDF for t to fit x\n",
    "#\n",
    "\n",
    "#\n",
    "# Scaling t to x space\n",
    "#\n",
    "\n",
    "x_vector = np.linspace(np.min(data.Compressive_Strength_28dy),\n",
    "                       np.max(data.Compressive_Strength_28dy),\n",
    "                       100)\n",
    "\n",
    "t_vector = np.linspace(-3,3,101)\n",
    "\n",
    "\n",
    "z_pdf = stats.norm.pdf(x_vector,\n",
    "                       np.mean(data.Compressive_Strength_28dy),  # mean goes here (loc in the docs)\n",
    "                       np.std(data.Compressive_Strength_28dy))   # stdev goes here (spread in the docs)\n",
    "\n",
    "\n",
    "t_vector_on_x = np.mean(data.Compressive_Strength_28dy) + t_vector *  np.std(data.Compressive_Strength_28dy)/np.sqrt(data_count)\n",
    "\n",
    "#\n",
    "# Overlaying the the PDF for t over our histogram.  \n",
    "#  (We also have our normal distribution overlayed atop it)\n",
    "#\n",
    "# \n",
    "#\n",
    "\n",
    "plt.hist(data.Compressive_Strength_28dy, \n",
    "         density = True,\n",
    "         color   = \"r\")\n",
    "plt.plot(t_vector_on_x, t_pdf_df, \"b\")\n",
    "plt.plot(x_vector,\n",
    "         z_pdf,\n",
    "         \"k\")\n",
    "plt.title(\"Yeh Concrete Tests (density)\")\n",
    "plt.xlabel(\"28-dy Compressive Strength (Pa)\")\n",
    "plt.ylabel(\"Probability Density, p(x)\")\n",
    "plt.legend([\"$p(\\mu_x)$\",\n",
    "            \"$p_{norm}(x)$\",\n",
    "            \"Data Histogram\"])\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we look at this plot, we can clearly see that the confidence intervals on the mean of our distribution are markedly tigher around the mean than the normal distribution for x.\n",
    "\n",
    "Recall that to get the two-tail area under the curve that enclosing 95% of the data, we target the right-side end of the enclosed area so for a 95% confidence interval we can just grab the cumulative distribution of our t distirbution and get the value where it's at $1-\\alpha/2$ which for us is 97.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Fetching our 95% confidence T-Statistic (inverse cdf for 0.975)\n",
    "#\n",
    "\n",
    "#\n",
    "#  Degrees of freedom (n-1)\n",
    "\n",
    "\n",
    "#\n",
    "#  Our Alpha Collection\n",
    "\n",
    "\n",
    "#\n",
    "#  Our Inverse of T for a cdf prob of 1-alpha/2\n",
    "\n",
    "\n",
    "\n",
    "print(\"Our t-statistic is \")\n",
    "print()\n",
    "\n",
    "#\n",
    "# And finally we can scale our t for our dataset\n",
    "#\n",
    "\n",
    "\n",
    "print(\"t s / sqrt(n) = \")\n",
    "print()\n",
    "print(\"confidence limit range: \")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Now let's do a linear regression on the Compressional Strength vs Cement Amount.\n",
    "\n",
    "This is much more complicated a process than working in R or Mathcad.  \n",
    "\n",
    "The best tool here is a library called [scikit-learn](https://scikit-learn.org/stable/).  This package is outside of the normal python ecosystem that people expect but is widely used. They also [rightfully] request to be cited when it's used so...\n",
    "\n",
    "\n",
    "Pedregosa, F. et al., 2011: Scikit-learn: Machine Learning in Python, *Journal of Machine Learning Research*, **12**, 2825-2830.\n",
    "\n",
    "\n",
    "Here we are going to use scikit-learn's [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) resource to manage the regression.  Getting scores are done using a different area of sklearn, [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Linear Regression with scikit-learn\n",
    "#\n",
    "# Here we will use the machine learning resource with scikit-learn\n",
    "#\n",
    "\n",
    "# To start we need a very simple pair of arrays for our x and y data\n",
    "\n",
    "# the double [[]]'s will take what would have been a horizontal vector \n",
    "#   into a vertical one\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# for referecne let's make a new degree of freedom value\n",
    "#\n",
    "\n",
    "\n",
    "# We now need to create an \"empty\" linear regression object\n",
    "#  this object will contain most of the tools we will\n",
    "#  need to create the linear regression.\n",
    "\n",
    "\n",
    "# now we use the fit our observalues of x and y together.\n",
    "\n",
    "\n",
    "\n",
    "# calculate the fitted y values to your input values\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for Linear Regression\n",
    "\n",
    "There are a set of tools in scikit-learn and honestly I really don't like them.  The only one that has helped me is the r_squared function.  I'll include a couple examples of their usage here, but  I prefer just using the basic equations.\n",
    "\n",
    "\n",
    "* Sum of the Squared Totals: $SST = \\sum{\\left(  y - \\bar{y}  \\right)^2}$\n",
    "\n",
    "* Sum of the Squared Residuals: $SSR = \\sum{\\left[  y - \\hat{y}\\left(\\vec{x}\\right)  \\right]^2}$\n",
    "\n",
    "* Standard Error of the Estimate:  $s_{yx} = \\sqrt{\\frac{SSR}{n-p-1}}$\n",
    "\n",
    "* Root Mean Square Error: $RMSE = \\sqrt{MSE} = \\sqrt{\\frac{SSR}{n}}$\n",
    "\n",
    "* Coef of Determination: $r^2 = \\frac{SSR-SST}{0-SST} = \\frac{SST-SSR}{SST} =  1 - \\frac{SSR}{SST}$\n",
    "\n",
    "* Adjusted Coef of Determination (for multivarate regression): $r_{adj}^2 = 1 - \\frac{SSR / (n-p-1)}{SST / (n-1)} $\n",
    "\n",
    "* CI Range for $\\hat{y}(x)$: $\\hat{y}(x) \\pm t_{\\alpha/2,df} s_{yx} \\sqrt{ \\frac{1}{n} + \\frac{ \\left( x-\\bar{x} \\right)^2 }{\\sum{\\left( x-\\bar{x} \\right)^2}} }$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Linear Regression Metrics with scikit-learn\n",
    "#\n",
    "\n",
    "#\n",
    "# Let's first get those variables into scalar form\n",
    "#   from a dataframe into a single value \n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print the summary of results.\n",
    "print(\"    Num of Obs: \")\n",
    "print(\"Deg of Freedom: \")\n",
    "print(\"           SST: \")\n",
    "print(\"           SSR: \")\n",
    "print(\"           MSE: \")\n",
    "print(\"          RMSE: \")\n",
    "print(\"           sxy: \")\n",
    "print(\"     R-squared: \")\n",
    "print(\"         Skill: \")\n",
    "print(\"   t_statistic: \")\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Things Out\n",
    "#\n",
    "# We're doing this one element at a \n",
    "# Make a sorted range for the x-axis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Create two intermediate steps for calculating\n",
    "#   CI for linear regression\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot it all... \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Regression\n",
    "\n",
    "Now let's try a multivariate regression using all of our independant variables that we pulled from above.\n",
    "\n",
    "The Linear Regression method from above can be applied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# For a multivariate regression we will do the same \n",
    "#   thing as above \n",
    "#\n",
    "\n",
    "#    Get the Y value\n",
    "\n",
    "\n",
    "#    For the X vector we are just using earlier indep. data\n",
    "#      dataframe (data_indep)  \n",
    "\n",
    "\n",
    "#\n",
    "#  Degrees of freedom (n-p)  (p includes dep and indep fields)\n",
    "#\n",
    "\n",
    "\n",
    "# We now need to create another empty linear regression \n",
    "#  object this object will contain most of the tools we \n",
    "#  will need to create the linear regression.\n",
    "\n",
    "\n",
    "# now we use the fit our observalues of x and y together.\n",
    "\n",
    "\n",
    "\n",
    "# calculate the fitted y values\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Multivariate Linear Regression Metrics \n",
    "#\n",
    "\n",
    "#\n",
    "# Get the variables into scalar form\n",
    "#   from a dataframe into a single value \n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print the summary of results.\n",
    "print(\"    Num of Obs: \")\n",
    "print(\"Deg of Freedom: \")\n",
    "print(\"           SST: \")\n",
    "print(\"           SSR: \")\n",
    "print(\"           MSE: \" )\n",
    "print(\"          RMSE: \")\n",
    "print(\"           sxy: \")\n",
    "print(\" Adj.R-squared: \")\n",
    "print(\"         Skill: \")\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Plotting Things Out\n",
    "#\n",
    "# We're doing this one element at a time\n",
    "#\n",
    "\n",
    "# make an high-y and low-y for our 1:1\n",
    "\n",
    "\n",
    "# Plot the data as blue dots\n",
    "\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "# Loading Version Information\n",
    "#\n",
    "\n",
    "%load_ext version_information\n",
    "\n",
    "%version_information version_information, numpy, matplotlib, pandas, xlrd, scipy, sklearn\n",
    "\n",
    "#\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
